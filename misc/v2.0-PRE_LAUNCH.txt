PRE_LAUNCH.txt
===============
see about rollback of book#read_for loookup process.  If I can tag book dups such that only one book of same author::title combination can online.  see migrate_v2.0_dup_bookmarks.js and .rb

DONE finish dev pre-launch dry run
DONE commit translation changes
test on dev and push to vr1
dry run of pre-launch on vr1?

# DONE suspend scoutapp monitoring
  https://scoutapp.com/jhancock/notifications
# DONE stop vr1 nginx
  sudo service nginx start
# DONE stop lin1 nginx

# DONE dump lin1 mongo.  cp to vr1

# DONE DNS stuff - lin1 to vr1
#   remove critsend DKIM and SPF

# migrate data
cd ~/migrate_v2.0
# rm -rf *
rm ~/migrate_v2.0.txt
cd ~/rails
rails r lib/scripts/migrate_v2.0/migrate_v2.0.rb  ~/mongo_dump/lin1-20141127051346.tar.gz ~/migrate_v2.0 > ~/migrate_v2.0.txt

# next three scripts handle duplicate books, bookmarks and users. 

rails r lib/scripts/migrate_v2.0/migrate_v2.0_dup_books.rb

# bookmarks 1303 dups, 834 have same chunk
#  keep most recent based on updated_at.  delete other.
rails r lib/scripts/migrate_v2.0/migrate_v2.0_dup_bookmarks.rb

# users 24 dups
#  keep most recent based on updated_at.  delete other.
rails r lib/scripts/migrate_v2.0/migrate_v2.0_dup_users.rb

### END SCRIPTS ###

# verify mongodb imported correct using robomongo

# create indexes.
rake db:mongoid:create_indexes

# from rails console
User.set_public_id_all
Bookmark.set_pp_all
Book.set_detail_li_all

quit

# remove indexes
rake db:mongoid:remove_indexes

# dump db
cd ~/migrate_v2.0
rm -rf v2/
mongodump --out ~/migrate_v2.0/v2

# drop db
# from mongo shell
mongo
use mhd_development || use mhd_production
db.dropDatabase()
quit()

# change model index defs (the ones commented out) of user, bookmark
# when doing above on vr1, commit index mods to git

# import db
# mongorestore -d mhd_development ~/migrate_v2.0/v2/mhd_development
# mongorestore -d mhd_production ~/migrate_v2.0/v2/mhd_production

# create indexes.
cd ~/rails
rake db:mongoid:create_indexes

# set mongodb profiling level
mongo
use mhd_development || use mhd_production
db.setProfilingLevel(2)
quit()

# index elastic search.  
rails r lib/scripts/reindex_book_search.rb

# after dry run, change the comments in model indexes of user and bookmark back to what they were so you can do the process again.

# SERVER READY

TODO create sitemap.xml.  create_sitemap.rb

verify SSL at https://www.ssllabs.com/

mandrill
  DONE ensure production API key
  DONE money in mandrill account
  DONE ensure mandrill DKIM and SPF
  change webhook urls to match mihudie.com, not vr1.mihudie.com

DONE remove basic auth from Rails
  ApplicationController before_action :http_auth

DONE nginx.conf
  change passenger_pre_start http://vr1.mihudie.com/; 
      to passenger_pre_start http://mihudie.com/; 

DONE nginx sites-available mihudie.com
  remove server_name vr1.mihudie.com;

DONE cp nginx.conf and mihudie.com conf files to /etc/nginx/...

DONE nginx mihudie.com config location for static files needs to have expires max working.  It may be commeted out pre-production.

DONE # rails log must be owned by group syslog or it won't rotate
rm ~/rails/log/*
touch ~/rails/log/production.log
sudo chown mhd:syslog ~/rails/log/production.log

DONE # delete old nginx logs
# /var/log/nginx/*

DONE # delete mongodb logs
sudo killall -SIGUSR1 mongod
sudo su -
cd /var/log/mongodb
# delete old rotated log file

DONE nginx gzip js and css files
      gzip -1 -c mihudie.css > mihudie.css.gz
      gzip -1 -c mihudie.js > mihudie.js.gz

DONE reboot vr1

DONE scoutapp
  change URL monitoring to mihudie.com and remove http auth params
  start monitoring

DONE adujst url monitoring on uptimerobot
  remove auth params

remove mihudie.com DNS setting on home wifi router

POST_LAUNCH
-------------
run SSL tests  testssl.com?

verify http working
curl -I http://mihudie.com

test microdata
http://www.google.com/webmasters/tools/richsnippets

submit site to baidu, google, bing, yahoo

cp lin1 nginx logs
